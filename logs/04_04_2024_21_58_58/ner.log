[ 2024-04-04 21:58:59,911 ] 85 root - INFO - Started Model training >>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[ 2024-04-04 21:58:59,911 ] 32 root - INFO - Entered the start_data_ingestion method of TrainPipeline class
[ 2024-04-04 21:58:59,911 ] 34 root - INFO - Getting the data from Google cloud storage
[ 2024-04-04 21:58:59,911 ] 48 root - INFO - Entered the initiate_data_ingestion method of data ingestion class
[ 2024-04-04 21:58:59,911 ] 56 root - INFO - Created DataIngestionArtifacts directory.
[ 2024-04-04 21:58:59,911 ] 21 root - INFO - Entered the get_data_from_gcp method of data ingestion class
[ 2024-04-04 21:59:06,849 ] 26 root - INFO - Exited the get_data_from_gcp method of data ingestion class
[ 2024-04-04 21:59:06,850 ] 66 root - INFO - Got the file from Google cloud storage. File name - archive.zip
[ 2024-04-04 21:59:06,851 ] 33 root - INFO - Entered the extract_data method of Data ingestion class
[ 2024-04-04 21:59:06,911 ] 41 root - INFO - Exited the extract_data method of Data ingestion class
[ 2024-04-04 21:59:06,911 ] 75 root - INFO - Extracted the data from zip file.
[ 2024-04-04 21:59:06,911 ] 81 root - INFO - Exited the initiate_data_ingestion method of data ingestion class
[ 2024-04-04 21:59:06,911 ] 39 root - INFO - Got the data from Google cloud storage
[ 2024-04-04 21:59:06,911 ] 40 root - INFO - Exited the start_data_ingestion method of TrainPipeline class
[ 2024-04-04 21:59:06,911 ] 55 root - INFO - Entered the start_data_transformation method of TrainPipeline class
[ 2024-04-04 21:59:06,911 ] 65 root - INFO - Entered the initiate_data_transformation method of Data transformation class
[ 2024-04-04 21:59:06,911 ] 74 root - INFO - Created DataTransformationArtifacts directory.
[ 2024-04-04 21:59:07,041 ] 30 root - INFO - Entered the splitting_data method of Data transformation class
[ 2024-04-04 21:59:07,041 ] 49 root - INFO - Exited the splitting_data method of Data transformation class
[ 2024-04-04 21:59:07,041 ] 87 root - INFO - Splitted the data
[ 2024-04-04 21:59:07,041 ] 93 root - INFO - Saved the labels to ids pickle file to Artifacts directory. File name - labels_to_ids.pkl
[ 2024-04-04 21:59:07,041 ] 101 root - INFO - Saved the ids to labels pickle file to Artifacts directory. File name - ids_to_labels.pkl
[ 2024-04-04 21:59:09,624 ] 110 root - INFO - Uploaded the ids to labels pickle file to Google cloud storage. File name - ids_to_labels.pkl
[ 2024-04-04 21:59:09,624 ] 118 root - INFO - Saved the train df pickle file to Artifacts directory. File name - df_train.pkl
[ 2024-04-04 21:59:09,624 ] 125 root - INFO - Saved the val df pickle file to Artifacts directory. File name - df_val.pkl
[ 2024-04-04 21:59:09,624 ] 133 root - INFO - Saved the test df pickle file to Artifacts directory. File name - df_test.pkl
[ 2024-04-04 21:59:09,624 ] 141 root - INFO - Saved the unique labels pickle file to Artifacts directory. File name - unique_labels.pkl
[ 2024-04-04 21:59:09,624 ] 153 root - INFO - Exited the initiate_data_transformation method of Data transformation class
[ 2024-04-04 21:59:09,631 ] 68 root - INFO - Performed the data validation operation
[ 2024-04-04 21:59:09,632 ] 69 root - INFO - Exited the start_data_transformation method of TrainPipeline class
